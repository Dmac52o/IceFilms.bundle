import re, urlparse, cgi, time, urllib, urllib2, stringfrom datetime import datefrom BeautifulSoup import BeautifulSoup	USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_2) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/534.51.22'def NormalizeURL(url):	#Log("*********** In VidhHog normalizeURL")		# Deal with special providerInfo URL built up by plugin to return	# info about this provider. For all other normal URLs, do nothing. 	if ("providerinfo" in url):			try:			show = Prefs["show_vidhog"]		except Exception, ex:			show = False				if (show):			return url + "&visible=true"		else:			return url				else:		return url	def MetadataObjectForURL(url): 	#Log('In MetadataObjectForURL for VidHog (' + url + ')')		# LMWT Plugin should have access to info about this URL if user used plugin to launch video.	video = LMWTGetVideoClipObjectFromMediaInfo(url)	if video is None:			video = VideoClipObject(			title = 'VidHog Redirect Page',			summary = 'VidHog Redirect Page',			thumb = None,		)		return video	def MediaObjectsForURL(url):	#Log('In MediaObjectsForURL for MovShare (' + url + ')')		return [		MediaObject(			parts = [PartObject(key=Callback(PlayVideo, url=url))],		)	]	@indirect	def PlayVideo(url):	# This used to handle the wait delay on the intial page by breaking 	# down the process into a two step process and returning back to	# the main plugin after the 1st step. Check file history if that	# ever needs to be brought back.		url_parts = urlparse.urlparse(url)	embed_url = urlparse.ParseResult(url_parts.scheme, url_parts.netloc, "/embed-" + url_parts.path[1:] + ".html", "", "", "").geturl()		# Request URL	soup = BeautifulSoup(		HTTP.Request(			embed_url,			cacheTime = 0		).content	)			#Log(soup)	if (soup.find('div',{'id':'player_code'}).a is not None):		final_url = soup.find('div',{'id':'player_code'}).a['href']	else:			player_code = soup.find('div',{'id':'player_code'}).find(text=re.compile("eval\(function\(p,a,c,k,e,d\)"))		player_code = Unpack(str(player_code))		#Log(player_code)			# There's a couple of different pages lying about....		if ('new SWFObject' in player_code):			final_url = re.search("\\\\'file\\\\',\\\\'([^\\\\]*)",player_code).group(1)		else:			soup = BeautifulSoup(re.search('(<.*>)', player_code).group(1))			final_url = soup.find('param',{'name': 'src'})['value']		Log(final_url)				oc = ObjectContainer(		objects = [			VideoClipObject(				items = [					MediaObject(						parts = [PartObject(key=final_url)]					)				]			)		]	)	# Might as well set a sensible user agent string.	oc.user_agent = USER_AGENT		return oc		def LogProviderError(msg="", ex=None):	Log("************************** PROVIDER ERROR: " + msg)	return []	def Unpack(script):	if script is None:		return		#Log(script)	# Look for string to unpack.	val_to_unpack = re.search("return p}\('(.*)',\d*,\d*,'", script)			if (val_to_unpack is None or val_to_unpack.group(1) is None):		return None		# Look for substitution values.	sub_vals = re.search("\d{2},'([^']*)'.split", script)		if (sub_vals is None):		return None		val_to_unpack = val_to_unpack.group(1)	sub_vals = sub_vals.group(1).split('|')	#Log(val_to_unpack)	#Log(sub_vals)		# Create dict to map url sub keys to sub values.	alphadict = dict()	for index_cnt in range(0, 2):		index = index_cnt * len(string.digits + string.ascii_lowercase)		strindex = str(index_cnt) if index_cnt > 0 else ""		for cnt in range(0, len(string.digits + string.ascii_lowercase)):			alphadict[strindex + (string.digits + string.ascii_lowercase)[cnt]] = cnt + index		def SubElem(matchObj):		val = sub_vals[alphadict[matchObj.group(0)]]		if (val == ""):			val = matchObj.group(0)		return val	# Sub values into string to unpack	return re.sub("[0-9a-z]{1,2}", SubElem, val_to_unpack) 	